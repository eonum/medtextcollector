{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Quality Classification\n",
    "\n",
    "Classifiy sentences into high / low quality. This is used to improve data quality for texts from different sources (scanned PDFs, crawled HTML, parsed Wikipedia, ..). It's mainly used to filter out artifacts from faulty parsing, HTML fragments, navigation elements, non-sentences (references, titles, ..)\n",
    "\n",
    "This notebook uses BERT for this task. Other approaches can be found in sentence_quality_classifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import load_config\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "### define a new configuration\n",
    "config_dict = {\n",
    "    # training data\n",
    "    \"train_file\": \"data/sentence-quality-8k.csv\",\n",
    "    \"seq_len\": 128,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 5,\n",
    "    \"lr\": 1e-4,\n",
    "    \n",
    "    # where to store the configuration file\n",
    "    \"config_path\": \"data/configuration-sentence-quality-classifier-bert.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### save config file (don't change)\n",
    "config_src = config_dict[\"config_path\"]\n",
    "\n",
    "with open(config_src, 'w+') as f:\n",
    "    json.dump(config_dict, f, indent=4)\n",
    "    \n",
    "# load config object based on config file (don't change)\n",
    "config = load_config.Configuration(config_src, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(config['train_file']) \n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 8007\n",
      "Number of sentences with label: 8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['LOW_QUALITY', 'REFERENCE', 'SENTENCE', 'TITLE', 'FOREIGN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFHCAYAAACoKpuzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naKgUgIiIhkoBiIhoqBSAiIiG+v8DBrIHoTCchwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f943477e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set targets\n",
    "print(\"Number of sentences: \" + str(len(data.index)))\n",
    "data = data.dropna(subset= ['Klassierung'])\n",
    "print(\"Number of sentences with label: \" + str(len(data.index)))\n",
    "data.groupby('Klassierung').Klassierung.count().plot.bar()\n",
    "\n",
    "#data['label'] = pd.Series(['high' if a else 'low' for a in data['Klassierung'].isin(['SENTENCE'])], index=data.index)\n",
    "data['label'] = pd.Series(data['Klassierung'], index=data.index)\n",
    "\n",
    "# set label / classes\n",
    "classes = list(data['label'].unique())\n",
    "data.head()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tim/.keras/datasets/multi_cased_L-12_H-768_A-12/bert_config.json /home/tim/.keras/datasets/multi_cased_L-12_H-768_A-12/bert_model.ckpt /home/tim/.keras/datasets/multi_cased_L-12_H-768_A-12/vocab.txt\n",
      "Vocabulary size: 119548\n"
     ]
    }
   ],
   "source": [
    "# Load BERT model\n",
    "from keras_bert import Tokenizer\n",
    "import keras\n",
    "from keras_bert import get_base_dict, get_model, gen_batch_inputs\n",
    "from keras_bert import get_pretrained, PretrainedList, get_checkpoint_paths\n",
    "import codecs\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "\n",
    "model_path = get_pretrained(PretrainedList.multi_cased_base)\n",
    "paths = get_checkpoint_paths(model_path)\n",
    "print(paths.config, paths.checkpoint, paths.vocab)\n",
    "\n",
    "token_dict = get_base_dict()  # A dict that contains some special tokens\n",
    "with codecs.open(paths.vocab, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "        \n",
    "print(\"Vocabulary size: \" + str(len(token_dict)))\n",
    "\n",
    "model = load_trained_model_from_checkpoint(\n",
    "    paths.config,\n",
    "    paths.checkpoint,\n",
    "    training=True,\n",
    "    trainable=False,\n",
    "    seq_len=config[\"seq_len\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 128, 119547)  119547      MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 128, 119547)  0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 178,271,741\n",
      "Trainable params: 0\n",
      "Non-trainable params: 178,271,741\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert data\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "indices = []\n",
    "for sentence in data[\"Satz\"]:\n",
    "    ids, segments = tokenizer.encode(sentence, max_len=config[\"seq_len\"])\n",
    "    indices.append(ids)\n",
    "indices = np.array(indices)\n",
    "target_indices = np.array([1 if target==\"SENTENCE\" else 0 for target in data[\"label\"]])\n",
    "\n",
    "#train / test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(indices, target_indices, random_state = 2)\n",
    "\n",
    "# input is an array of the token indices and an array of the segment indices\n",
    "# (which is 0 for all tokens in this task)\n",
    "segments_test = np.zeros_like(X_test)\n",
    "segments_train = np.zeros_like(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Custom Model / Add softmax layer for sentence classification on top\n",
    "import keras\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "\n",
    "inputs = model.inputs[:2]\n",
    "dense = model.get_layer('NSP-Dense').output\n",
    "outputs = keras.layers.Dense(units=2, activation='softmax')(dense)\n",
    "\n",
    "decay_steps, warmup_steps = calc_train_steps(\n",
    "    y_train.shape[0],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    epochs=config[\"epochs\"],\n",
    ")\n",
    "\n",
    "model = keras.models.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    AdamWarmup(decay_steps=decay_steps, warmup_steps=warmup_steps, lr=config[\"lr\"]),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 91812096    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            1538        NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 177,560,066\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 177,558,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6003/6003 [==============================] - 38s 6ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5317\n",
      "Epoch 2/5\n",
      "6003/6003 [==============================] - 36s 6ms/step - loss: 0.6890 - sparse_categorical_accuracy: 0.5376\n",
      "Epoch 3/5\n",
      "6003/6003 [==============================] - 37s 6ms/step - loss: 0.6893 - sparse_categorical_accuracy: 0.5354\n",
      "Epoch 4/5\n",
      "6003/6003 [==============================] - 37s 6ms/step - loss: 0.6872 - sparse_categorical_accuracy: 0.5491\n",
      "Epoch 5/5\n",
      "6003/6003 [==============================] - 37s 6ms/step - loss: 0.6864 - sparse_categorical_accuracy: 0.5542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9330c4f7f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [X_train, segments_train],\n",
    "    y_train,\n",
    "    epochs=config[\"epochs\"],\n",
    "    batch_size=config[\"batch_size\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002/2002 [==============================] - 14s 7ms/step\n",
      "0.5469530469530469\n"
     ]
    }
   ],
   "source": [
    "predicts = model.predict([X_test, segments_test], verbose=True).argmax(axis=-1)\n",
    "print(np.sum(y_test == predicts) / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
